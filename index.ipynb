{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to validate your model using train-test-split.\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Calculate the mean squared error (MSE) as a measure of predictive performance\n",
    "- Validate the model using the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use our Boston Housing Data again!\n",
    "\n",
    "This time, let's only include the variables that were previously selected using recursive feature elimination. We included the code to preprocess below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "b = boston_features[\"B\"]\n",
    "logdis = np.log(boston_features[\"DIS\"])\n",
    "loglstat = np.log(boston_features[\"LSTAT\"])\n",
    "\n",
    "# minmax scaling\n",
    "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n",
    "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n",
    "\n",
    "#standardization\n",
    "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_features[['CHAS', 'RM', 'DIS', 'B', 'LSTAT']]\n",
    "y = pd.DataFrame(boston.target,columns = [\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>0.542096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.275260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.263711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>0.623954</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>-1.627858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>-2.153192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0.707895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.162114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE       DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  0.542096  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  0.623954  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  0.623954  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  0.707895  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  0.707895  3.0  222.0   \n",
       "\n",
       "   PTRATIO         B     LSTAT  \n",
       "0     15.3  1.000000 -1.275260  \n",
       "1     17.8  1.000000 -0.263711  \n",
       "2     17.8  0.989737 -1.627858  \n",
       "3     18.7  0.994276 -2.153192  \n",
       "4     18.7  1.000000 -1.162114  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_features.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply your model to the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and initializing the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model to the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating predictions on the train set, and on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train = lr.predict(X_train)\n",
    "y_hat_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating your residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the Mean Squared Error\n",
    "A good way to compare overall performance is to compare the mean squarred error for the predicted values on the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.785630985428533\n",
      "19.797937587211422\n"
     ]
    }
   ],
   "source": [
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print(train_mse)\n",
    "print(test_mse)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your test error is substantially worse then our train error, this is a sign that our model doesn't generalize well to future cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simple way to demonstrate overfitting and underfitting is to alter the size of our train test split. By default, scikit learn's built in method allocates 25% of the data to the test set and 75% to the training set. Fitting a model on only 10% of the data is apt to lead to underfitting, while training a model on 99% of the data is apt to lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the effect of train-test split size\n",
    "\n",
    "Iterate over a range of train-test split sizes from .5 to .95. For each of these, generate a new train/test split sample. Fit a model to the training sample and calculate both the training error and the test error (mse) for each of these splits. Plot these two curves (train error vs. training size and test error vs. training size) on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa3cc28b470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(11)\n",
    "\n",
    "train_err = []\n",
    "test_err = []\n",
    "t_sizes = list(range(5,100,5))\n",
    "for t_size in t_sizes:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size/100)\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_hat_train = lr.predict(X_train)\n",
    "    y_hat_test = lr.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.scatter(t_sizes, train_err, label='Training Error')\n",
    "plt.scatter(t_sizes, test_err, label='Testing Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the effect of train-test split size: extension\n",
    "\n",
    "Repeat the previous example, but for each train-test split size, generate 100 iterations of models/errors and save the average train/test error. This will help account for any particularly good/bad models that might have resulted from poor/good splits in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linreg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-8b3c932a8a66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_size\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0my_hat_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my_hat_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linreg' is not defined"
     ]
    }
   ],
   "source": [
    "random.seed(8)\n",
    "\n",
    "train_err = []\n",
    "test_err = []\n",
    "t_sizes = list(range(5,100,5))\n",
    "for t_size in t_sizes:\n",
    "    temp_train_err = []\n",
    "    temp_test_err = []\n",
    "    for i in range(100):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size/100)\n",
    "        linreg.fit(X_train, y_train)\n",
    "        y_hat_train = linreg.predict(X_train)\n",
    "        y_hat_test = linreg.predict(X_test)\n",
    "        temp_train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "        temp_test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "    train_err.append(np.mean(temp_train_err))\n",
    "    test_err.append(np.mean(temp_test_err))\n",
    "plt.scatter(t_sizes, train_err, label='Training Error')\n",
    "plt.scatter(t_sizes, test_err, label='Testing Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? evaluate your result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now practiced your knowledge on MSE and on using train-test-split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
